{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import metrics, stem, tokenize \n",
    "import string\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/osboxes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/osboxes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/osboxes/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cellopub.txt', 'r') as infile, open ('./cellopub_edit.txt', 'w') as outfile:\n",
    "    for line in infile:\n",
    "        line = line.replace(\"NeferiNE   reverses\",\"NeferiNE reverses\")\n",
    "        outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diccionarios que se van a rellenar con la información de las referencias y líneas celulares\n",
    "ids ={}\n",
    "titles={}\n",
    "abts={}\n",
    "\n",
    "abstracts=[] \n",
    "title=[]\n",
    "a='No'\n",
    "file_cell = open ('./cellopub_edit.txt', 'r')\n",
    "file_cell.seek(0)\n",
    "cell_num=0\n",
    "\n",
    "#Almacenaje de la información del archivo de texto en los diccionarios\n",
    "\n",
    "for line in file_cell.readlines():\n",
    "    line = line.strip()\n",
    "    if line == '//':\n",
    "        if len(title) != 0:\n",
    "            total_tit = \" \".join(title) #todo el título se junta en una variable tipo string\n",
    "            titles[cell_num] = total_tit\n",
    "        \n",
    "        if a == 'Yes':\n",
    "            total_abs = \" \".join(abstracts) #todo el abstract se junta en una variable tipo string\n",
    "            abts[cell_num] = total_abs\n",
    "            \n",
    "        a='No' \n",
    "        abstracts=[] \n",
    "        title=[]\n",
    "        cell_num+=1\n",
    "        \n",
    "    elif re.search(r'^ID\\s{3}\\S+', line):\n",
    "        header, identif = line.split(\"   \")\n",
    "        ids[cell_num] = identif\n",
    "        \n",
    "            \n",
    "    elif re.search(r'^RT\\s{3}\\S+', line):\n",
    "        header, identif = line.split(\"   \")\n",
    "        title.append(identif)\n",
    "            \n",
    "    elif re.search(r'^AB\\s{3}\\S+', line):\n",
    "        header, identif = line.split(\"   \")\n",
    "        if identif == 'Yes':\n",
    "            a=identif\n",
    "            n=0\n",
    "        else:\n",
    "            a='No'\n",
    "\n",
    "    elif a == 'Yes':\n",
    "        abstracts.append(line)\n",
    "    \n",
    "    else:\n",
    "        continue     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de lineas celulares con publicación en cellopub.txt: 451, \n",
      "Número de títulos de las publicaciones en cellopub.txt: 411, \n",
      "Número de abstract de publicaciones en cellopub.txt: 271.\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de lineas celulares con publicación en cellopub.txt: %s, \\nNúmero de títulos de las publicaciones en cellopub.txt: %s, \\nNúmero de abstract de publicaciones en cellopub.txt: %s.\" % (len(ids.keys()), len(titles.keys()), len(abts.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open('./umls_corpus.csv', 'r') as infile, open ('./umls_corpus.tsv', 'w') as outfile:\n",
    "    for line in infile:\n",
    "        line = line.replace('\",\"','\"\\t\\t\"',1)\n",
    "        line = line.replace(',,,,,',' ')\n",
    "        line = line.replace(',,,,',' ')\n",
    "        line = line.replace(',,,',' ')\n",
    "        line = line.replace(',,',' ')\n",
    "        line = line.replace('^',' ')\n",
    "        line = line.replace('\\\\',' ')\n",
    "        line = line.replace('+',' ')\n",
    "        outfile.write(line)\n",
    "#El archivo umls_corpus.tsv tiene el código y la expresión de umls separados por dos tabuladores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "umls_codes={}\n",
    "file_umls = open ('./umls_corpus.tsv', 'r')\n",
    "for line in file_umls.readlines():\n",
    "    line = line.strip()\n",
    "    code, expression = line.split(\"\\t\\t\")\n",
    "    umls_codes[code]=expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de códigos de umls guardados: 334921\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de códigos de umls guardados: %s\" % (len(umls_codes.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para obtener únicamente el morfema de la palabra\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that drops conjunctions, preposition, uppercases and only returns the morfem of the word\n",
    "standard_words=['protein','enzyme','cell','structure','product','location', 'observable','without']\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = nltk.word_tokenize(text) #obtener palabras por separado\n",
    "    tokens = [token for token in tokens if len(token) > 3] #obtener solo palabras de más de 3 letras\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')] #se eliminan stopwords\n",
    "    tokens = [token for token in tokens if token not in standard_words] #se quitan palabras con poca relevancia\n",
    "    tokens = [get_lemma(token) for token in tokens] #se obtiene únicamente el morfema\n",
    "    tokens = [token.strip('+') for token in tokens] #eliminar signos +\n",
    "    tokens = [token.strip('*') for token in tokens] #eliminar signos *\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar códigos umls estándares\n",
    "umls_stand=[]\n",
    "umls_keys=[]\n",
    "for k in umls_codes.keys():\n",
    "    expression = umls_codes[k]\n",
    "    expression = re.sub('\\((\\w+)\\)',' ', expression)\n",
    "    expression = prepare_text_for_lda(expression)\n",
    "    umls_stand.append(expression)\n",
    "    umls_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para obtener los topics como palabras separadas\n",
    "def clean_topic(list_lda):\n",
    "    string=''.join(str(e) for e in list_lda)\n",
    "    topics=[]\n",
    "    sing_topics=[]\n",
    "    total_list_top = []\n",
    "    topics = string.split(\"+\")\n",
    "    for topic in topics:\n",
    "        val, top = topic.split(\"*\")\n",
    "        top = top.strip('\"')\n",
    "        top = top.strip('\" ')\n",
    "        top = top.strip('\"\\')')\n",
    "        sing_topics.append(top)\n",
    "    for word in sing_topics:\n",
    "        if word not in total_list_top:\n",
    "            total_list_top.append(word)\n",
    "    return (total_list_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para crear modelo con algoritmo lda\n",
    "def lda_model_topics(texts):\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 1, id2word=dictionary, passes=5)\n",
    "    list_top = (ldamodel.print_topics(num_topics=1, num_words=7)) #generar una lista de 7 palabras que describan el artículo\n",
    "    return(list_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para transformar una lista en dos\n",
    "def split_two(lst):\n",
    "    l_a=[]\n",
    "    l_b=[]\n",
    "    lmax = len(lst)\n",
    "    lmin = int(lmax/2)\n",
    "    for i in range(lmin):\n",
    "        l_a.append(lst[i])\n",
    "    for i in range(lmin,lmax):\n",
    "        l_b.append(lst[i])\n",
    "    return(l_a,l_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_info=[]\n",
    "topics={} #diccionario que va a contener los topics de cada línea celular\n",
    "\n",
    "for key in titles.keys():\n",
    "    title = titles[key]\n",
    "    title = prepare_text_for_lda(title)\n",
    "    total_info.append(title)\n",
    "    if key in abts.keys():                 #topics generados con la información del título y el abstract \n",
    "        abstr = abts[key]\n",
    "        abstr = prepare_text_for_lda(abstr)\n",
    "        total_info.append(abstr)\n",
    "        \n",
    "    else:\n",
    "        text_1, text_2 = split_two(title)   #topics generados con información del título (abstract no disponible)\n",
    "        total_info.append(text_1)\n",
    "        total_info.append(text_2)\n",
    "    \n",
    "    list_top=lda_model_topics(total_info)\n",
    "    list_top = clean_topic(list_top)\n",
    "    topics[key]=list_top\n",
    "    total_info=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función que asigna a cada tipo celular un código umls\n",
    "count = 0\n",
    "searches = 0\n",
    "list_ids_cells=[] #lista con los identificadores de las células de cellopub\n",
    "list_codes_umls=[] #lista con los códigos umls encontrados asociados a cada tipo celular\n",
    "\n",
    "for key in topics.keys():\n",
    "    topic = ' '.join(str(e) for e in topics[key])\n",
    "    for n in range(len(umls_stand)):\n",
    "        expression = umls_stand[n]\n",
    "        count=0\n",
    "        if expression != []:\n",
    "            for i in range(len(expression)):\n",
    "                word=expression[i]\n",
    "                if re.search(word, topic):    \n",
    "                    count += 1\n",
    "                    \n",
    "            if len(expression)<4:\n",
    "                if count == len(expression):\n",
    "                    if umls_keys[n] not in list_codes_umls:\n",
    "                        list_codes_umls.append(umls_keys[n])\n",
    "                        list_ids_cells.append(ids[key])\n",
    "                        searches += 1\n",
    "            else:\n",
    "                if count > (len(expression)-2):\n",
    "                    if umls_keys[n] not in list_codes_umls:\n",
    "                        list_codes_umls.append(umls_keys[n])\n",
    "                        list_ids_cells.append(ids[key])\n",
    "                        searches += 1\n",
    "        else:\n",
    "            continue     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_cells=[]\n",
    "for n in range(len(list_ids_cells)):\n",
    "    if list_ids_cells[n] not in total_number_cells:\n",
    "        total_number_cells.append(list_ids_cells[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos de códigos umls encontrados: 663\n",
      "Número de términos de líneas celulares diferentes para las que se ha encontrado término umls: 133\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de términos de códigos umls encontrados: %s\" % (len(list_codes_umls)))\n",
    "print(\"Número de términos de líneas celulares diferentes para las que se ha encontrado término umls: %s\" % (len(total_number_cells)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe con las líneas celulares y los códigos umls con los que se relacionan\n",
    "df_cell_umls = pd.DataFrame()\n",
    "df_cell_umls = pd.DataFrame(columns=['Cell_ID','UMLS_code'])\n",
    "df_cell_umls.Cell_ID=list_ids_cells\n",
    "df_cell_umls.UMLS_code=list_codes_umls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Cell_ID   UMLS_code\n",
      "0    CLPUB00222  \"C0010437\"\n",
      "1    CLPUB00222  \"C0014792\"\n",
      "2    CLPUB00222  \"C0037262\"\n",
      "3    CLPUB00222  \"C0230718\"\n",
      "4    CLPUB00222  \"C0230719\"\n",
      "5    CLPUB00222  \"C0237504\"\n",
      "6    CLPUB00222  \"C0324282\"\n",
      "7    CLPUB00222  \"C0324283\"\n",
      "8    CLPUB00222  \"C0348086\"\n",
      "9    CLPUB00222  \"C0412747\"\n",
      "10   CLPUB00222  \"C0424488\"\n",
      "11   CLPUB00222  \"C0428415\"\n",
      "12   CLPUB00222  \"C0446519\"\n",
      "13   CLPUB00222  \"C0446888\"\n",
      "14   CLPUB00222  \"C0446890\"\n",
      "15   CLPUB00222  \"C0447967\"\n",
      "16   CLPUB00222  \"C0448165\"\n",
      "17   CLPUB00222  \"C0449197\"\n",
      "18   CLPUB00222  \"C0449198\"\n",
      "19   CLPUB00222  \"C0449199\"\n",
      "20   CLPUB00222  \"C0449200\"\n",
      "21   CLPUB00222  \"C0449201\"\n",
      "22   CLPUB00222  \"C0449202\"\n",
      "23   CLPUB00222  \"C0449203\"\n",
      "24   CLPUB00222  \"C0449204\"\n",
      "25   CLPUB00222  \"C0449205\"\n",
      "26   CLPUB00222  \"C0449206\"\n",
      "27   CLPUB00222  \"C0449207\"\n",
      "28   CLPUB00222  \"C0449208\"\n",
      "29   CLPUB00222  \"C0449209\"\n",
      "..          ...         ...\n",
      "633  CLPUB00113  \"C0558356\"\n",
      "634  CLPUB00113  \"C2204475\"\n",
      "635  CLPUB00103  \"C0016163\"\n",
      "636  CLPUB00103  \"C0453076\"\n",
      "637  CLPUB00103  \"C0453078\"\n",
      "638  CLPUB00022  \"C0036499\"\n",
      "639  CLPUB00022  \"C0337023\"\n",
      "640  CLPUB00022  \"C2919405\"\n",
      "641  CLPUB00124  \"C0327981\"\n",
      "642  CLPUB00202  \"C0201930\"\n",
      "643  CLPUB00076  \"C0427631\"\n",
      "644  CLPUB00076  \"C1267821\"\n",
      "645  CLPUB00076  \"C1267833\"\n",
      "646  CLPUB00076  \"C1267834\"\n",
      "647  CLPUB00076  \"C1267841\"\n",
      "648  CLPUB00076  \"C1267843\"\n",
      "649  CLPUB00076  \"C1267846\"\n",
      "650  CLPUB00076  \"C1267849\"\n",
      "651  CLPUB00076  \"C1267853\"\n",
      "652  CLPUB00442  \"C0028429\"\n",
      "653  CLPUB00442  \"C0085349\"\n",
      "654  CLPUB00442  \"C0301973\"\n",
      "655  CLPUB00442  \"C0302291\"\n",
      "656  CLPUB00442  \"C0312655\"\n",
      "657  CLPUB00442  \"C0446625\"\n",
      "658  CLPUB00442  \"C1278896\"\n",
      "659  CLPUB00442  \"C1321760\"\n",
      "660  CLPUB00278  \"C0327853\"\n",
      "661  CLPUB00278  \"C0443969\"\n",
      "662  CLPUB00328  \"C1301808\"\n",
      "\n",
      "[663 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_cell_umls) #dataframe que contiene los códigos umls de todas las las referencias de las líneas celulares\n",
    "\n",
    "df_cell_umls.to_csv('cell_umls.csv', sep = '\\t', index = False) #exportar dataframe a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
